{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-kensyo2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obara13/ml-test/blob/master/pytorch-bert-classification-test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwkRbaBHycwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pandas torch transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCkeeNgorVAa",
        "colab_type": "text"
      },
      "source": [
        "# Load training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVQmB7SPzMDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = 'data/'\n",
        "df_train = pd.read_csv(DATA_PATH + 'train.csv')\n",
        "#df_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9S33uMYrZq1",
        "colab_type": "text"
      },
      "source": [
        "# Remove unnecessary words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gme7azY69Pzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "pattern = re.compile(r'https?://\\S*|@\\S*')\n",
        "\n",
        "for i in range(df_train.shape[0]):\n",
        "  df_train.loc[i, 'text']  = pattern.sub('', df_train.loc[i, 'text'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLr-QhWGrsiT",
        "colab_type": "text"
      },
      "source": [
        "# Check CPU or GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITMzaHkkzbHh",
        "colab_type": "code",
        "outputId": "76653be0-2c72-47b0-b6ed-8e804de520c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DamczSkJs0eW",
        "colab_type": "text"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntCF0JxxsyCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer, BertConfig, BertModel, BertForSequenceClassification\n",
        "\n",
        "#model_type = 'bert-base-multilingual-cased'\n",
        "model_type = 'bert-base-uncased'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_type)\n",
        "#config = BertConfig.from_json_file(BERT_CONFIG_PATH)\n",
        "model = BertForSequenceClassification.from_pretrained(model_type)\n",
        "\n",
        "#print(model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9dJuluVsHbo",
        "colab_type": "text"
      },
      "source": [
        "# Set classifier and bert last layer for trainable (require_grad = True), others for un-trainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFN9GTSX0Oxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for name, param in model.bert.encoder.layer[-1].named_parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for name, param in model.classifier.named_parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVdIogopsmcy",
        "colab_type": "text"
      },
      "source": [
        "# Prepare train data (pandas dataframe -> tensor dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kZeXDYY0jtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "ids = []\n",
        "labels = []\n",
        "max_length = 32\n",
        "batch_size = 32\n",
        "\n",
        "for i in range(df_train.shape[0]):\n",
        "  ids.append(tokenizer.encode(df_train.loc[i, 'text'],\n",
        "                              max_length=max_length, pad_to_max_length=True))\n",
        "  labels.append(df_train.loc[i, 'target'])\n",
        "\n",
        "input_ids = torch.tensor(ids).to(device)\n",
        "input_labels = torch.tensor(labels).to(device)\n",
        "\n",
        "train_data = TensorDataset(input_ids, input_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmvy-CZrtamz",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNo0VYok1ffk",
        "colab_type": "code",
        "outputId": "c2df5aa5-1a31-4b66-f73c-c57482718a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  total_eval = 0\n",
        "  correct = 0\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    if step*batch_size/df_train.shape[0] < 0.7:  # train\n",
        "      model.train().to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(batch[0], labels=batch[1])\n",
        "      loss = outputs[0]\n",
        "      total_loss += loss.item()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #if step % 100 == 0:\n",
        "      #  print(step, ':%6.1f' % (time.time() - t0), ':', loss.item())  \n",
        "    else:   # eval\n",
        "      model.eval().to(device)\n",
        "      with torch.no_grad():\n",
        "        outputs = model(batch[0])\n",
        "      for i, pred in enumerate(outputs[0]):\n",
        "        total_eval += 1\n",
        "        if pred.argmax().item() == batch[1][i].item():\n",
        "          correct += 1\n",
        "\n",
        "  print(epoch, ': %6.1f' % (time.time() - t0),\n",
        "        ', loss: ', total_loss,\n",
        "        ', accr: ', correct/total_eval)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 :   10.8 , loss:  82.2471664249897 , accr:  0.8267959453503746\n",
            "1 :   21.5 , loss:  71.35702998936176 , accr:  0.8289995592772146\n",
            "2 :   32.1 , loss:  69.79170575737953 , accr:  0.8439841339797267\n",
            "3 :   42.8 , loss:  65.35116255283356 , accr:  0.8329660643455267\n",
            "4 :   53.3 , loss:  64.65896537899971 , accr:  0.8497135301895108\n",
            "5 :   64.0 , loss:  64.34797659516335 , accr:  0.8497135301895108\n",
            "6 :   74.6 , loss:  63.37654058635235 , accr:  0.8514764213309828\n",
            "7 :   85.3 , loss:  58.50173069536686 , accr:  0.8391361833406787\n",
            "8 :   95.9 , loss:  62.504255175590515 , accr:  0.8594094314676068\n",
            "9 :  106.5 , loss:  60.94529316574335 , accr:  0.8501542529748788\n",
            "10 :  117.2 , loss:  59.561195224523544 , accr:  0.8554429263992949\n",
            "11 :  127.9 , loss:  58.41919145733118 , accr:  0.8501542529748788\n",
            "12 :  138.7 , loss:  58.65693661570549 , accr:  0.8655795504627589\n",
            "13 :  149.3 , loss:  57.52973356842995 , accr:  0.8682238871749669\n",
            "14 :  160.0 , loss:  56.5433104634285 , accr:  0.872190392243279\n",
            "15 :  170.7 , loss:  57.30958741903305 , accr:  0.881886293521375\n",
            "16 :  181.3 , loss:  55.48949509114027 , accr:  0.8065226972234465\n",
            "17 :  192.0 , loss:  55.94513241946697 , accr:  0.873512560599383\n",
            "18 :  202.7 , loss:  54.96002238988876 , accr:  0.880564125165271\n",
            "19 :  213.4 , loss:  54.55345568060875 , accr:  0.8862935213750551\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}